A pretrained SAE-HD model is simply a model that has been trained on a large dataset of different faces. They are often trained up to 1m iterations sometimes, and because of this, they can be used a base model to dramatically speed up training on a new src or dst. This is because the model already knows what a human face looks like, has seen it in many conditions/angles and different face types. The preview is reset, so you won't actually be able to see it's prior knowledge visually, but it is there. I recall once being told that, training from a pretrained will never be as good as training from scratch, even though it does speed up training so dramatically that the quality difference would be more than worth it, if not neglible anyway. For that reason, I say you should pretty much always use them, unless it's a very niche case (training animated characters or someone with glasses/piercings).

Pretrained XSEG is a model for masking the generated face, very helpful to automatically and intelligently mask away obstructions. All you need to do is pop it in your model folder along with the other model files, use the option to apply the XSEG to the dst set, and as you train you will see the src face learn and adapt to the DST's mask. Just make sure you select learned-dst when merging the frames.

RTT (Ready To Train) is, simply put, a model that has been reused many times, with different dst or src, or in some cases even both. To start out a RTT, you can simply copy the pretrain set .pak file from _internal dir into your aligned folders. U can use a pretrained model but since this is basically the same as pretraining, it's not necessary. Train until the faces look well defined (teeth are sharp), 1m should be fine, there wont be any high frequency detail yet. No reason to change any of the default settings during this state in my experience. After this, you can save a copy of it, and train any dst or src and it will very quickly adapt to anything you throw at it, sometimes even better than a regular trained model would. Many say this can't be done with DF-UD but it definitely can, I've done it. It probably does work better with LIAE, though. What's really cool is, the model has a very far back memory that can reimplement knowledge that it learned from many training sessions ago, for example if you wanted to return back to a dst/src that you used previously with the same model, it will be faster if the model has already seen that face in the past. Eventually, the model can forget things as I hear.

RTM (Ready To Merge) is a model that has been trained specifically to apply one specific face to very wide variety of possible dsts. To do this, a large src set is used, encompassing as many angles/lighting/expressions as physically possible, and its trained against a RTM or pretrain faceset. This allows the model learn how to apply the face to any type of face shape, expression or lighting condition. Creating one of these can at times allow you to completely skip the training step, because you can just plop it into your model file, and merge to an extracted dst without a src set or training required. This is because it already knows exactly how to approximate the face in dst because of its prior knowledge. This should be done with LIAE models as they have better architecture for adapting to different face shapes/lighting but I suppose theoretically it could be done with DF. These can also be used like RTM and retrained with a new DST to basically instantaneously adapt, if for example there's a few kinks that need to be worked with merging without training. PS, this is a major oversimplification , refer to the official DFL guide for step by step instructions on how to perfect an RTM model.

The official DFL guide should encompass most of this, I thought. Some of this may be wrong so am open to corrections.